# Temario del Curso

30 clases organizadas en 4 fases.

---

## Fase 1: Fundamentos (Clases 1-11)

| # | Tema | Descripción |
|:-:|------|-------------|
| 1 | Introducción e Historia | Definición de inteligencia, arco histórico de la IA, paradigmas |
| 2 | Agents y Environments | Abstracción central: percibir → decidir → actuar, framework PEAS |
| 3 | Lógica | Razonamiento con certeza, lógica proposicional, inferencia |
| 4 | Computación | Límites computacionales, Turing machines, P vs NP |
| 5 | Probabilidad | Razonamiento bajo incertidumbre, desiderata de Jaynes, Bayes |
| 6 | Fat Tails | Cuando fallan los supuestos: LLN, CLT, distribuciones fat-tail |
| 7 | Information Theory I | Entropy, surprise, conditional entropy |
| 8 | Information Theory II | KL divergence, cross-entropy, principio MDL |
| 9 | Optimización | Landscapes, gradient descent, convexity, Lagrangian |
| 10 | Taxonomía de Predicción | Marco de 5 dimensiones para organizar métodos predictivos |
| 11 | Decision Theory | Expected utility, axiomas de racionalidad, value of information |

---

## Fase 2: Inference y Search (Clases 12-18)

| # | Tema | Descripción |
|:-:|------|-------------|
| 12 | Causality | Structural causal models, do-calculus, confounding |
| 13 | Bayesian Inference | Actualización de creencias, Bayesian networks, d-separation |
| 14 | Monte Carlo Methods | Sampling para aproximar expectativas, importance sampling |
| 15 | Informed Search | Heuristics, algoritmo A*, admissibility |
| 16 | Adversarial Search | Game trees, minimax, alpha-beta pruning |
| 17 | Simulation-Based Planning | Monte Carlo Tree Search, rollouts |
| 18 | Classical Planning | Representación STRIPS, forward planning |

---

## Fase 3: Sequential y Strategic Decisions (Clases 19-24)

| # | Tema | Descripción |
|:-:|------|-------------|
| 19 | Constraints y Local Search | CSPs, propagation, hill climbing, simulated annealing |
| 20 | Markov Models y HMMs | Markov property, chains, forward y Viterbi algorithms |
| 21 | MDPs I | Definición, Bellman equation, policies |
| 22 | MDPs II | Value iteration, policy iteration, policy extraction |
| 23 | Game Theory I | Normal form, dominant strategies, Nash equilibrium |
| 24 | Game Theory II | Repeated games, folk theorem, torneo de Axelrod |

---

## Fase 4: Learning y RL (Clases 25-30)

| # | Tema | Descripción |
|:-:|------|-------------|
| 25 | Learning Theory | Generalization, bias-variance tradeoff, regularization |
| 26 | Neural Networks | Perceptron, multilayer networks, backpropagation |
| 27 | RL I | Exploration vs exploitation, bandits, ε-greedy, UCB |
| 28 | RL II | Temporal difference, Q-learning, SARSA |
| 29 | RL III | Function approximation, DQN, policy gradients |
| 30 | Síntesis | Integración del curso, selección de métodos, fronteras |
